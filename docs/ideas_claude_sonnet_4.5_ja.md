# AI Vtuber Phase 2 提案書
**著者**: Claude Sonnet 4.5
**日付**: 2025-12-26
**ターゲット**: Week 2 開発における高インパクトな機能群

---

## 1. 現状アーキテクチャ分析

### 強み
- **関心の分離が明確**: インターフェース主導設計（`IChatAdapter`, `ILLMService`, `ITTSService`）により、テストや拡張が容易。
- **堅牢なエラーハンドリング**: エラー抑制機能（Agent.tsの再試行・ログ抑制）により、API障害時もログが荒れない。
- **自然なタイミング**: ランダムなディレイ（独り言間隔、発話前の「間」）により、機械的な不自然さを回避している。
- **優先度付きキュー**: 割り込み処理（Interruption）が高優先度で処理され、即応性がある。
- **モジュラーなプロンプト**: PromptManagerによるテンプレートベースのプロンプト生成が機能している。

### 重大な弱点

#### 1. **会話メモリの状態不保持 (Stateless)**
- **問題**: 各LLM呼び出しが過去のやり取りを全く知らない。
- **影響**: 過去の話題を参照したり、視聴者の好みを覚えたり、文脈のある会話ができない。
- **証拠**: `buildReplyPrompt` は現在のコメントしか渡していない。

#### 2. **単純すぎるコメント分類**
- **問題**: CommentRouterが正規表現（?やw）のみで判断している。
- **影響**: 皮肉、ニュアンスのある質問、文脈依存の意図を汲み取れない。
- **例**: "That's great..."（皮肉）が、REACTIONではなくOFF_TOPIC（無視）に分類される恐れ。

#### 3. **静的な人格**
- **問題**: プロンプトが固定テンプレートで、動的な調整がない。
- **影響**: 配信のムード（盛り上がり/まったり）や視聴者層に合わせてトーンを変えられない。
- **機会損失**: 感情状態のモデリングがされていない。

#### 4. **視覚的統合の欠如**
- **問題**: 音声出力のみで、画面（Live2D等）との連動がない。
- **影響**: 現代のVtuberに求められる「動き」や「表情」がない。リップシンクもない。

#### 5. **直線的な話題進行**
- **問題**: TopicSpineが一本道のリスト構造である。
- **影響**: 盛り上がった話題を深掘りしたり、バイラルなトピックに飛びつく柔軟性がない。

---

## 2. 提案機能 (Phase 2)

### 機能1: **ベクトル埋め込みを用いたエピソード記憶システム**

#### コンセプト
二層のメモリオアーキテクチャを実装する：
- **短期記憶 (STM)**: 直近20件のメッセージ（インメモリ）。
- **長期記憶 (LTM)**: 全配信にわたるセマンティック検索可能な永続ベクトルDB。

#### 価値
- **継続性**: 「先週話したReactの件だけど…」といった会話が可能。
- **パーソナライズ**: 「@TechGuruさん、お帰り！Dockerの調子はどう？」
- **文脈**: 「さっきみんなが『草』って連呼してた時〜」のような振り返り。

#### 技術アプローチ
**スタック**:
- **Chroma** (`chromadb`) - TypeScript対応の軽量ベクトルDB。
- **OpenAI Embeddings** (`text-embedding-3-small`) - 安価で高性能。
- **SQLite** - メタデータ保存用。

**実装イメージ**:
(コード等の詳細は原文参照)

**統合**:
- `PromptManager` に「直近の会話」「関連する過去の記憶」セクションを追加・注入する。

---

### 機能2: **信頼度スコア付きLLMインテント分類**

#### コンセプト
正規表現ルーターを軽量LLM分類器に置き換え、以下を出力させる：
- インテントカテゴリ (質問/反応/脱線/スパム)
- 信頼度スコア (0-1)
- 緊急度フラグ (>0.8なら独り言を中断)

#### 価値
- **精度向上**: 疑念を含む質問などを正確に「質問」として拾える。
- **文脈理解**: ジョーク後の「www」は反応、脈絡のない「www」はスパム、等。
- **低レイテンシ**: `gpt-4o-mini` で高速化。

#### 技術アプローチ
- GPT-4o-mini の Structured Outputs (JSONモード) を使用。
- 信頼度 < 0.6 なら保留キューへ送る、といったフィルタリングが可能。
- キャッシュ活用でコスト削減。

---

### 機能3: **動的感情ステートマシン (Dynamic Emotional State Machine)**

#### コンセプト
内部に「気分(Mood)」システムを持ち、以下に影響させる：
- 音声合成パラメータ (pitch, speed)
- 返答のトーン (興奮/冷静)
- 話題選択の優先度
- (将来的に) 色相・表情

**状態**: `NEUTRAL | EXCITED | THOUGHTFUL | AMUSED | CONFUSED | TIRED`

#### 価値
- **実在感**: レイドで盛り上がったり、深い話で落ち着いたりする人間らしさ。
- **没入感**: 感情の推移（ストーリーアーク）が生まれる。

#### 技術アプローチ
- **感情エンジン**: コメント流量やポジティブ単語数から感情値を遷移させるクラスを実装。
- **プロンプト統合**: `You are feeling EXCITED...` のようにシステムプロンプトに現在の感情を注入。
- **VOICEVOX連携**: `speed_scale` や `pitch_scale` を感情に合わせて動的に変更。

---

### 機能4: **スマートピボット付きマルチモーダル話題グラフ**

#### コンセプト
TopicSpine（リスト）を「有向グラフ」に置き換える。
- トピックはノード（所要時間・前提知識タグ付き）。
- エッジは遷移可能性。
- チャットの興味に合わせて、関連トピックへ「ジャンプ」できる。

#### 価値
- **柔軟性**: Dockerの話からKubernetesの話へ、チャットの流れで自然に移行できる。
- **参加感**: 視聴者が話題をコントロールしている感覚を持てる。

---

### 機能5: **Live2D + OBS WebSocket 統合**

#### コンセプト
AIの発話と視覚出力を同期させる。
- TTSの音素タイミングを使ったリップシンク。
- 感情エンジン連動の表情変更。
- 引用やコードをOBS上にオーバーレイ表示。

#### 価値
- **プロ品質**: 静止画ではなく「動く」Vtuberへ。
- **アクセシビリティ**: 視覚情報（字幕・資料）の補完。

#### 技術アプローチ
- **OBS WebSocket**: シーン・ソース制御。
- **VTube Studio API**: Live2Dモデル制御。

---

## 3. 開発ロードマップ (Day 7-14)

### Week 2 Sprint Plan

#### **Day 7: 記憶の基盤**
- Chroma DB導入、MemoryService実装。
- 直近5件の会話を覚えられるようにする。

#### **Day 8: LLMインテント分類**
- `LLMCommentRouter` 実装 (GPT-4o-mini)。
- 正規表現からの移行と精度検証。

#### **Day 9: 感情エンジン (Part 1)**
- `EmotionalState` 定義、状態遷移ロジック実装。
- コンソールログで感情変化を確認。

#### **Day 10: 感情エンジン (Part 2)**
- プロンプトへの感情注入、VOICEVOXパラメータ連動。
- 30分のテスト配信で自然さを確認。

#### **Day 11-12: 話題グラフ (Topic Graph)**
- トピックグラフの設計と実装。
- チャット内容に基づく動的な話題遷移ロジック。

#### **Day 13: 視覚統合 (OBS)**
- OBS WebSocket接続。
- テキストオーバーレイの実装・テスト。

#### **Day 14: 仕上げ & 統合テスト**
- 全機能（記憶＋感情＋グラフ＋OBS）を通した動作確認。
- パフォーマンスチューニング。

---

## 4. "Killer" Differentiator (差別化要因)

### **「参加型ストーリーテリング・モード」**

#### コンセプト
配信の特定パートで、AIと視聴者がリアルタイムに物語を共作する。
- AIが「設定」を提示（例：「幽霊屋敷のコードデバッグ」）。
- 視聴者が「展開」をチャットで提案（例：「バグの正体はAIだった！」）。
- LLMがそれを統合し、物語を紡ぐ。
- **複数の声色**（VOICEVOXの話者切り替え）を使って、AIがキャラを演じ分ける。
- OBSのシーンも物語に合わせて切り替わる。

#### なぜこれがキラー機能なのか
1. **文脈管理**: 高度な記憶が必要。
2. **創造性**: 単なるQ&Aではない、クリエイティブなLLM活用。
3. **多声類**: VOICEVOXの特性（多話者）を最大限活かせる。
4. **没入感**: 視聴者が「物語の作家」になれる体験は、他の自動配信にはない。

---

## 結論
このPhase 2ロードマップにより、単なる「自動応答bot」から、**記憶・感情・物語を持ったエンターテイナー**へと進化します。
特に「ストーリーテリングモード」は、技術的にも体験的にも非常にユニークな強みとなります。
